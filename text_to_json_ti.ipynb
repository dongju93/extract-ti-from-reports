{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from env import *\n",
    "from whitelist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_path = text_path\n",
    "output_path = json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_references(content):\n",
    "    reference_name_pattern = re.compile(r'CVE-\\d{4}-\\d{4,5}', re.IGNORECASE)\n",
    "    return [match.upper() for match in re.findall(reference_name_pattern, content)]\n",
    "\n",
    "# Custom rules for non-English filename\n",
    "def extract_filenames(content):\n",
    "    filename_pattern = re.compile(r'\\b\\w+\\.[a-zA-Z]{2,4}\\b')\n",
    "    potential_filenames = re.findall(filename_pattern, content)\n",
    "    cleaned_filenames = []\n",
    "    for filename in potential_filenames:\n",
    "        name, ext = filename.rsplit('.', 1)\n",
    "        english_part = re.search('[a-zA-Z]+$', name)\n",
    "        if english_part:\n",
    "            name = english_part.group()\n",
    "        cleaned_filenames.append(f\"{name}.{ext}\")\n",
    "    return cleaned_filenames\n",
    "\n",
    "def extract_md5(content): \n",
    "    md5_pattern = re.compile(r'\\b[0-9a-fA-F]{32}\\b')\n",
    "    return re.findall(md5_pattern, content)\n",
    "\n",
    "def extract_sha1(content): \n",
    "    sha1_pattern = re.compile(r'\\b[0-9a-fA-F]{40}\\b')\n",
    "    return re.findall(sha1_pattern, content)\n",
    "\n",
    "def extract_sha256(content): \n",
    "    sha256_pattern = re.compile(r'\\b[0-9a-fA-F]{64}\\b')\n",
    "    return re.findall(sha256_pattern, content)\n",
    "\n",
    "def extract_registry_entries(content):\n",
    "    registry_pattern = re.compile(r'HK[A-Z_]+\\\\[^\"\\n]+')\n",
    "    return re.findall(registry_pattern, content)\n",
    "\n",
    "def extract_urls(content):\n",
    "    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    # return re.findall(url_pattern, content)\n",
    "     # Find all URLs\n",
    "    urls = re.findall(url_pattern, content)\n",
    "    \n",
    "    # Remove [ and ] from the extracted URLs\n",
    "    cleaned_urls = [url.replace(\"[\", \"\").replace(\"]\", \"\") for url in urls]\n",
    "    \n",
    "    return cleaned_urls\n",
    "\n",
    "\n",
    "# weight is Dummy\n",
    "def categorize_content(content, rule_id, filename):\n",
    "    # Extracting data from content\n",
    "    references = extract_references(content)\n",
    "    samples = extract_filenames(content)\n",
    "\n",
    "    return {\n",
    "        'rule_id': rule_id,\n",
    "        'name': filename[:-4],\n",
    "        'description': \"-\",\n",
    "        'references': extract_references(content),\n",
    "        'samples': extract_filenames(content),\n",
    "        'MD5' : extract_md5(content),\n",
    "        'SHA1' : extract_sha1(content),\n",
    "        'SHA256' : extract_sha256(content),\n",
    "        'Registry_Entries': extract_registry_entries(content),\n",
    "        'URLs': extract_urls(content),\n",
    "        'weight': 0.0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read text files\n",
    "def get_text_files_from_directory(directory_path):\n",
    "    return [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.txt')]\n",
    "\n",
    "# Save json files\n",
    "def write_to_json(output_path, content):\n",
    "    with open(output_path, \"w\") as outfile:\n",
    "        # json.dump(content, outfile)\n",
    "        json.dump(content, outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique content for each files\n",
    "def process_text_file(file_path, unique_sets, rule_id):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        content = file.read()\n",
    "        filename = os.path.basename(file_path)\n",
    "        categorized_content = categorize_content(content, rule_id, filename)\n",
    "\n",
    "        categorized_content['references'] = list(set([x for x in categorized_content['references'] if x not in unique_sets['references']]))\n",
    "        unique_sets['references'].update(categorized_content['references'])\n",
    "\n",
    "        categorized_content['samples'] = list(set([x for x in categorized_content['samples'] if x not in unique_sets['samples'] and not any(whitelisted in x for whitelisted in whitelist_file_names)]))\n",
    "        unique_sets['samples'].update(categorized_content['samples'])\n",
    "\n",
    "        categorized_content['Registry_Entries'] = list(set([x for x in categorized_content['Registry_Entries'] if x not in unique_sets['Registry_Entries']]))\n",
    "        unique_sets['Registry_Entries'].update(categorized_content['Registry_Entries'])\n",
    "\n",
    "        categorized_content['MD5'] = list(set([x for x in categorized_content['MD5'] if x not in unique_sets['MD5']]))\n",
    "        unique_sets['MD5'].update(categorized_content['MD5'])\n",
    "\n",
    "        categorized_content['SHA1'] = list(set([x for x in categorized_content['SHA1'] if x not in unique_sets['SHA1']]))\n",
    "        unique_sets['SHA1'].update(categorized_content['SHA1'])\n",
    "\n",
    "        categorized_content['SHA256'] = list(set([x for x in categorized_content['SHA256'] if x not in unique_sets['SHA256']]))\n",
    "        unique_sets['SHA256'].update(categorized_content['SHA256'])\n",
    "\n",
    "        categorized_content['URLs'] = list(set([x for x in categorized_content['URLs'] if x not in unique_sets['URLs'] and not any(whitelisted in x for whitelisted in whitelist_urls)]))\n",
    "        unique_sets['URLs'].update(categorized_content['URLs'])\n",
    "\n",
    "        # merge into signatures category\n",
    "        keys_to_combine = ['MD5', 'SHA1', 'SHA256', 'Registry_Entries', 'URLs']\n",
    "        categorized_content['signatures'] = [item for key in keys_to_combine for item in categorized_content.get(key, [])]\n",
    "        \n",
    "        return categorized_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule_id is auto incresement\n",
    "def process_all_text_files(directory_path, output_path):\n",
    "    text_files = get_text_files_from_directory(directory_path)\n",
    "    unique_sets = {\n",
    "        'references': set(),\n",
    "        'samples': set(),\n",
    "        'Registry_Entries': set(),\n",
    "        'MD5': set(),\n",
    "        'SHA1': set(),\n",
    "        'SHA256': set(),\n",
    "        'URLs': set()\n",
    "    }\n",
    "    rule_id = 0\n",
    "    for file_path in text_files:\n",
    "        rule_id += 1\n",
    "        categorized_content = process_text_file(file_path, unique_sets, rule_id)\n",
    "        # Toggle remove fields\n",
    "        # for field in ['MD5', 'SHA1', 'SHA256', 'Registry_Entries', 'URLs']:\n",
    "        #     categorized_content.pop(field, None)\n",
    "        filename_without_extension = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_json_path = os.path.join(output_path, filename_without_extension + \".json\")\n",
    "        write_to_json(output_json_path, categorized_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excute\n",
    "process_all_text_files(directory_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
